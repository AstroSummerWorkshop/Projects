{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asteroid Tracking Workbook\n",
    "\n",
    "This workbook will guide you through measuring the precise RA and Dec coordinates (astrometry) of the asteroid 2013 GG69 on the night of June 19th, 2022. After making your measurements, you will input them into an orbit solver to visualize the orbit and find how frequently and closely the asteroid approaches Earth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "We need a relatively large number of packages for this workbook. These packages include functions that will do most of the really hard work for us, including measuring star positions and performing astrometric solving. The next cell includes all imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T00:23:49.369015Z",
     "iopub.status.busy": "2023-05-18T00:23:49.368393Z",
     "iopub.status.idle": "2023-05-18T00:23:49.384809Z",
     "shell.execute_reply": "2023-05-18T00:23:49.382863Z",
     "shell.execute_reply.started": "2023-05-18T00:23:49.368962Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/secretstorage/dhcrypto.py:15: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/usr/lib/python3/dist-packages/secretstorage/util.py:19: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "WARNING: Astrometry.net API key not found in configuration file [astroquery.astrometry_net.core]\n",
      "WARNING: You need to manually edit the configuration file and add it [astroquery.astrometry_net.core]\n",
      "WARNING: You may also register it for this session with AstrometryNet.key = 'XXXXXXXX' [astroquery.astrometry_net.core]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "from astropy.visualization import SqrtStretch\n",
    "from astropy.visualization.mpl_normalize import ImageNormalize\n",
    "from astropy.wcs import WCS\n",
    "from astropy.time import Time\n",
    "from datetime import datetime\n",
    "\n",
    "from astroquery.astrometry_net import AstrometryNet\n",
    "\n",
    "from photutils.aperture import CircularAperture\n",
    "from photutils.centroids import centroid_2dg\n",
    "from photutils.centroids import centroid_sources\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "\n",
    "from sow_tools import mask_bad_pix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cell is the base path where all the files for this project are located. Do not edit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T00:25:09.553126Z",
     "iopub.status.busy": "2023-05-18T00:25:09.552234Z",
     "iopub.status.idle": "2023-05-18T00:25:09.564792Z",
     "shell.execute_reply": "2023-05-18T00:25:09.561723Z",
     "shell.execute_reply.started": "2023-05-18T00:25:09.553062Z"
    }
   },
   "outputs": [],
   "source": [
    "store_path = 'raw/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to get the names of all the files we will be using. Edit the list definitions below with correct file names and locations.\n",
    "e.g. bias_files = ['file1.fits', 'file2.fits', etc...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bias_files = ['d1022.fits', 'd1023.fits', 'd1024.fits', 'd1025.fits', 'd1026.fits', 'd1027.fits', 'd1028.fits', 'd1029.fits', 'd1030.fits']\n",
    "flat_files = ['d1037.fits', 'd1038.fits', 'd1039.fits'] \n",
    "sci_files = ['d1065.fits', 'd1066.fits', 'd1067.fits', 'd1068.fits', 'd1069.fits', 'd1070.fits'] # science images that include asteroid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating main calibrations\n",
    "We want to average our individual calibration images together to make a main image that is more accurate than any of the individual images. To do this, we will read in the image data from each of our individual calibrations then take the median of every pixel value. It is better to take the median instead of a true average because the median is not changed by one large outlier, while an average is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edit the code below to create a main bias image and save it in the main_bias variable\n",
    "Reference the data reduction workbook or ask an instructor for help if you aren't sure what to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bias_data = np.empty((9,1024,1056))\n",
    "for i, file in enumerate(bias_files):\n",
    "    hdu = fits.open(store_path+file)\n",
    "    bias_data[i] = hdu[0].data\n",
    "    hdu.close()\n",
    "\n",
    "main_bias = np.nanmedian(bias_data,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ddcd13f687c4d99a39e5e519b9111d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "med_bval = np.nanmedian(main_bias)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(main_bias, vmin=med_bval*0.98, vmax=med_bval*1.02, origin='lower')\n",
    "plt.colorbar()\n",
    "plt.title('Main bias image', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the same but for the flat images. Save the image in the main_flat variable.\n",
    "Remember that each individual flat image needs the main_bias subtracted from it before they are combined together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T01:49:06.787990Z",
     "iopub.status.busy": "2023-05-02T01:49:06.787530Z",
     "iopub.status.idle": "2023-05-02T01:49:07.844786Z",
     "shell.execute_reply": "2023-05-02T01:49:07.842450Z",
     "shell.execute_reply.started": "2023-05-02T01:49:06.787941Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "flat_data = np.empty((3,1024,1056))\n",
    "for i, file in enumerate(flat_files):\n",
    "    hdu = fits.open(store_path+file)\n",
    "    bias_sub = (hdu[0].data - main_bias)\n",
    "    \n",
    "    flat_data[i] = bias_sub / np.nanmedian(bias_sub)\n",
    "    hdu.close()\n",
    "\n",
    "main_flat = np.nanmedian(flat_data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36d44f1d608144fda056d53809d5ba90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "med_fval = np.nanmedian(main_flat)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(main_flat, vmin=med_fval*0.9, vmax=med_fval*1.1, origin='lower')\n",
    "plt.colorbar()\n",
    "plt.title('Main flat image', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Correcting our science images with the main calibrations\n",
    "Here we will use our main bias and main flat images to correct all of the science images containing the asteroid. The science images are loaded for you, but you need to input the math for correcting it into the loop. \n",
    "In addition, we will use a function **mask_bad_pix** to remove bax pixels and cosmic rays from our science images. This function is already written, you simply need to give it the corrected image as the **sci_im** variable.\n",
    "\n",
    "At the end of this cell, we save important information from the .fits header including the time that the observations occurred and where the telescope was roughly pointing in RA and Dec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T21:13:52.476848Z",
     "iopub.status.busy": "2023-05-02T21:13:52.476178Z",
     "iopub.status.idle": "2023-05-02T21:14:00.080324Z",
     "shell.execute_reply": "2023-05-02T21:14:00.078002Z",
     "shell.execute_reply.started": "2023-05-02T21:13:52.476792Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_sci = len(sci_files)\n",
    "sci_data = np.empty((num_sci,1024,1024))\n",
    "sci_coords = np.empty((num_sci,2))\n",
    "time_data = []\n",
    "for i, file in enumerate(sci_files):\n",
    "    # loop through all science files\n",
    "    hdu = fits.open(store_path+file)\n",
    "    \n",
    "    sci_im = hdu[0].data ### FIXME ###\n",
    "    \n",
    "    # mask_bad_pix will search for significant outliers in our data and remove them, we also remove an unneeded overscan region of the images\n",
    "    sci_data[i] = mask_bad_pix(sci_im)[0:1024,0:1024]\n",
    "    \n",
    "    # write the corrected science files into new .fits files that will be saved\n",
    "    tmp = fits.PrimaryHDU(sci_data[i], header=hdu[0].header)\n",
    "    tmpl = fits.HDUList(tmp)\n",
    "    tmpl.writeto(store_path+file.strip('.fits')+'_calib.fits', overwrite=True)\n",
    "    tmpl.close()\n",
    "    \n",
    "    # we also want to save some values from the .fits header that we need for astrometric measurements\n",
    "    # grab the approximate RA and Dec pointing of the telescope\n",
    "    sci_coords[i] = hdu[0].header['CRVAL2S'], hdu[0].header['CRVAL1S'] \n",
    "    # get the beginning and end time of each exposure\n",
    "    time_data.append([Time(hdu[0].header['DATE-BEG'], format='isot', scale='utc'), Time(hdu[0].header['DATE-END'], format='isot', scale='utc')]) \n",
    "    \n",
    "    # close and go to the next image\n",
    "    hdu.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guessing star locations for an astrometric image solution\n",
    "In the next few cells, we will work on providing astrometry.net the information it needs to give us an astrometric solution for each of our images. The most fundamental information that astrometry.net is the pixel positions of all the stars in the image. We could use a package to automatically identify all the stars, however, this can be somewhat difficult because if we accidentally identify some random noise as a star then it will be impossible be astrometry.net to find a solution since we've given it one or more stars that don't actually exist.\n",
    "\n",
    "To be safer, we can manually identify the approximate pixel locations of sources we know are stars, then refine their positions with another package before giving them to astrometry.net."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pyds9 TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prelim_sources = []#FIXME#FIXME#FIXME\n",
    "\n",
    "prelim_sources = np.array(prelim_sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Telling astrometry.net our CCD scale\n",
    "astrometry.net will find a solution much faster if we tell it the dimensions of our images and the rough pixel scale (what fraction of an arcsecond each pixel covers)\n",
    "\n",
    "Find this information in the manual for the Nickel Direct Imaging Camera - https://mthamilton.ucolick.org/techdocs/instruments/nickel_direct/intro/\n",
    "\n",
    "**Important -** all our images are taken with 2x pixel binning, which means the size of the detector is reduced by half and the pixel scale is doubled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T22:58:12.400393Z",
     "iopub.status.busy": "2023-05-18T22:58:12.398546Z",
     "iopub.status.idle": "2023-05-18T22:58:12.445657Z",
     "shell.execute_reply": "2023-05-18T22:58:12.442128Z",
     "shell.execute_reply.started": "2023-05-18T22:58:12.400234Z"
    }
   },
   "outputs": [],
   "source": [
    "image_width = #FIXME\n",
    "image_height = #FIXME\n",
    "\n",
    "plate_scale = #FIXME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using astrometry.net requires an API key associated to a registered account. This is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = 'svigftgopyhezcqs'\n",
    "ast = AstrometryNet()\n",
    "ast.api_key = api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refining sources and getting astrometric solutions!\n",
    "Now we are ready to loop through our images and get an astrometric solution for each one. The next cell contains the loop.\n",
    "\n",
    "At the beginning of the loop, we first use the centroid_sources function to precisely refine the pixel locations of stars we identified previously. For every image, we will go ahead and plot a red circle around the location of identified stars, that we can see if any stars are detected that shouldn't be.\n",
    "\n",
    "Next, we will get the astrometric solution with the ast.solve_from_source_list() function. Here we pass it the star positions and the CCD parameters that we also found earlier. We also give it the rough RA and Dec pointing of the telescope so that astrometry.net doesn't have to search the entire sky for a matching pattern of stars. In general, astrometry.net can find solutions with very little information, but it goes much faster the more information we provide it.\n",
    "\n",
    "ast.solve_from_source_list() returns the astrometry in a World Coordinate System (WCS) 'header' format, which we will put into a list for every image. These headers don't directly contain the astrometry for our asteroid, but contain all the information we need later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcs_list = []\n",
    "    \n",
    "for i, data in enumerate(sci_data):\n",
    "    \n",
    "    x, y = centroid_sources(data, prelim_sources[:,0], prelim_sources[:,1], box_size=21,\n",
    "                        centroid_func=centroid_2dg)\n",
    "\n",
    "    positions = np.transpose((x, y))\n",
    "    apertures = CircularAperture(positions, r=4.0)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(data, origin='lower', vmin=0, vmax=30,\n",
    "               interpolation='nearest')\n",
    "    apertures.plot(color='red', lw=1.5, alpha=1.0)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    \n",
    "    wcs_header = ast.solve_from_source_list(x, y,\n",
    "                                            image_width, image_height,\n",
    "                                            solve_timeout=120, scale_units='arcsecperpix', scale_type='ev', scale_est=scale_est, scale_err=0.01,\n",
    "                                            center_dec=sci_coords[i,0], center_ra=sci_coords[i,1], radius=1.0, parity=2)\n",
    "    wcs_list.append(wcs_header)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell is to check that all our astrometric solutions were successful. **If an error is returned, at least one solution was not successful** - get assistance from the instructor to identify what is going wrong before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert any(elem is None for elem in wcs_list) == False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring the asteroid positions\n",
    "We have an astrometric solution for our images, but we still need to measure the actual pixel positions of our asteroid to convert to RA and Dec with the solutions.\n",
    "\n",
    "Below we will once again loop through our images and use the DAOStarFinder function to find the asteroid position. \n",
    "\n",
    "To make this easier, **set a range of x and y values in the image that will only contain the asteroid and no other sources**. The upper range and lower ranges correspond to the top and bottom pixel values that will bound the box containing our asteroid.\n",
    "\n",
    "As before, we will plot a red circle on the identified source in each image. **Check that the circle is on the asteroid for every plot**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_lower_range = #FIXME\n",
    "x_upper_range = #FIXME\n",
    "y_lower_range = #FIXME\n",
    "y_upper_range = #FIXME\n",
    "\n",
    "src_list = []\n",
    "\n",
    "for i, data in enumerate(sci_data):\n",
    "    strip = data[y_lower_range:y_upper_range, x_lower_range:x_upper_range]\n",
    "    mean, median, std = sigma_clipped_stats(strip, sigma=3.0)\n",
    "\n",
    "    daofind = DAOStarFinder(fwhm=5.0, threshold=5.*std)  \n",
    "    sources = daofind(strip - median) \n",
    "    src_list.append([sources['xcentroid'], sources['ycentroid']])\n",
    "    \n",
    "    positions = np.transpose((sources['xcentroid'], sources['ycentroid']))\n",
    "    apertures = CircularAperture(positions, r=4.0)\n",
    "    norm = ImageNormalize(stretch=SqrtStretch())\n",
    "    plt.imshow(strip, origin='lower', norm=norm,\n",
    "               interpolation='nearest')\n",
    "    apertures.plot(color='red', lw=1.5, alpha=1.0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting position to asteroid astrometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
